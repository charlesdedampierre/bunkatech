{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e65ca1a-8fa5-4aad-9aab-ebd52a276a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bamboolib\n",
    "\n",
    "from bunkatech.nested_topic_modeling import nested_topic_modeling\n",
    "\n",
    "path = '/Volumes/OutFriend/citypop'\n",
    "comments = pd.read_csv(path + '/reddit/comments.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ee63ba3e-ad89-4d7b-9c4c-aff31cdbd714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings..\n",
      "Territory embedding..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6e6f244c654ed78c4fc18e245c5224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing the vectors..\n",
      "UMAP(angular_rp_forest=True, metric='cosine', n_components=5, n_neighbors=10, verbose=True)\n",
      "Sat Feb 19 22:57:13 2022 Construct fuzzy simplicial set\n",
      "Sat Feb 19 22:57:19 2022 Finding Nearest Neighbors\n",
      "Sat Feb 19 22:57:20 2022 Finished Nearest Neighbor Search\n",
      "Sat Feb 19 22:57:20 2022 Construct embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5feb03ce4954abfa70e95c82bfa7dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/500 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 19 22:57:24 2022 Finished embedding\n",
      "Extract Terms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 2495/2495 [00:20<00:00, 121.45it/s]\n"
     ]
    }
   ],
   "source": [
    "bunka = nested_topic_modeling().fit(\n",
    "    comments,\n",
    "    text_var=\"body\",\n",
    "    index_var=\"id\",\n",
    "    sample_size=5000,\n",
    "    sample_terms=5000,\n",
    "    embeddings_model=\"sbert\",\n",
    "    ngrams=(2, 2),\n",
    "    ents=False,\n",
    "    language=\"en\",\n",
    "    db_path=\".\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61351f9-4b53-465f-9ea6-75a237e3bc6c",
   "metadata": {},
   "source": [
    "#### Find centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fa04dc1c-65de-4c58-bdba-34c51e71753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = bunka.h_clusters_names\n",
    "emb = bunka.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "efc66a0d-3428-4d84-bc0c-8ddc2e64a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb = pd.merge(df_clusters, emb.drop('level_0', axis=1), on = 'id')\n",
    "new_emb = df_emb.drop(['lemma_0', 'lemma_1', 'lemma_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca6827c2-c5d5-44f8-9646-d23b911a84f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def closest_point(centroid, matrix, n=2):\n",
    "    # Get the n closest points to the centroids\n",
    "    matrix = np.asarray(matrix)\n",
    "    dist_2 = np.sum((matrix - centroid)**2, axis=1)\n",
    "    point = np.argsort(dist_2)[:n]\n",
    "    return point\n",
    "\n",
    "def farest_point(centroid, matrix):\n",
    "    matrix = np.asarray(matrix)\n",
    "    dist_2 = np.sum((matrix - centroid)**2, axis=1)\n",
    "    point = np.argsort(dist_2)[-1]\n",
    "    #point = np.argmax(dist_2)\n",
    "    return point\n",
    "\n",
    "\n",
    "def find_centroids(df_fin, top_elements = 4, cluster_var = 'level_0', index_var = 'id'):\n",
    "\n",
    "\n",
    "    clusters = []\n",
    "    centroid_elements = []\n",
    "    far_elements = []\n",
    "    distances = []\n",
    "\n",
    "    for cluster in set(df_fin[cluster_var]):\n",
    "        clusters.append(cluster)\n",
    "\n",
    "        df_filter = df_fin[df_fin[cluster_var] == cluster]\n",
    "\n",
    "        # the matrix is the embedding (it can be any embedding)\n",
    "        matrix = df_filter[[0, 1, 2, 3, 4]].values\n",
    "\n",
    "        # Compute the centroid\n",
    "        centroid = np.average(matrix, axis=0)\n",
    "\n",
    "        # Find the index in the matrix of the clostest point\n",
    "        closest_index = closest_point(centroid, matrix, n=top_elements)\n",
    "\n",
    "         # Find the index in the matrix of the farest point\n",
    "        far_index = farest_point(centroid, matrix)\n",
    "\n",
    "        # find the distance bewteen the centroid and the farest point\n",
    "        distance =  np.linalg.norm(matrix[far_index] - matrix[closest_index])\n",
    "        distances.append(distance)\n",
    "\n",
    "        # find the corresponding element to the centroid in the metadata    \n",
    "        centroid_element = df_filter.iloc[closest_index][index_var].tolist()\n",
    "        if len(centroid_element) >= 1:\n",
    "            centroid_element = ' || '.join(centroid_element)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        centroid_elements.append(centroid_element)\n",
    "\n",
    "\n",
    "        # find the corresponding element to the farest point in the metadata\n",
    "        far_element = df_filter.iloc[far_index][index_var]\n",
    "        far_elements.append(far_element)\n",
    "\n",
    "    # Create a DataFrame with the elements\n",
    "    df_centroids = pd.DataFrame({cluster_var:clusters, \n",
    "                                 'centroid_element':centroid_elements, \n",
    "                                 'far_elements':far_elements, \n",
    "                                 'radius':distances})\n",
    "    return df_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e94ca229-6488-4ace-ba00-b8828dae2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centroids = find_centroids(new_emb, \n",
    "                              top_elements = 4, \n",
    "                              cluster_var = 'level_2', \n",
    "                              index_var = 'id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e754edc-ec3e-47fe-a247-4ce021e75ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f202dd08618402ca05a3481c2c964df"
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_2</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Wave | Pocket Music | Summer Days</td>\n",
       "      <td>Listen to the album of this. It is also good. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Big Wave | Pocket Music | Summer Days</td>\n",
       "      <td>It's my second favorite of his after Ride On T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Wave | Pocket Music | Summer Days</td>\n",
       "      <td>I like *Weekend Fly to the Sun* because every ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Big Wave | Pocket Music | Summer Days</td>\n",
       "      <td>Enjoy! My favorite track is “Street Dancer”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great Album | album ️ | nice album</td>\n",
       "      <td>So lucky I love love love this album . what a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Tatsuro Yamashita | OMEGA TRIBE | music ⭐</td>\n",
       "      <td>[tatsuro yamashita live at festival hall](http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>watch?v= | Akina Nakamori | MEIKO NAKAHARA</td>\n",
       "      <td>Koi No Projection\\tis one of my favs. [here it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>watch?v= | Akina Nakamori | MEIKO NAKAHARA</td>\n",
       "      <td>Compare to [Masayoshi Takanaka –  Star Wars Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>watch?v= | Akina Nakamori | MEIKO NAKAHARA</td>\n",
       "      <td>[Lonely Sunset](https://www.youtube.com/watch?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>watch?v= | Akina Nakamori | MEIKO NAKAHARA</td>\n",
       "      <td>Hideki Saijo - Careless Whisper\\n\\nhttps://www...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        lemma_2  \\\n",
       "0         Big Wave | Pocket Music | Summer Days   \n",
       "1         Big Wave | Pocket Music | Summer Days   \n",
       "2         Big Wave | Pocket Music | Summer Days   \n",
       "3         Big Wave | Pocket Music | Summer Days   \n",
       "4            Great Album | album ️ | nice album   \n",
       "..                                          ...   \n",
       "182   Tatsuro Yamashita | OMEGA TRIBE | music ⭐   \n",
       "183  watch?v= | Akina Nakamori | MEIKO NAKAHARA   \n",
       "184  watch?v= | Akina Nakamori | MEIKO NAKAHARA   \n",
       "185  watch?v= | Akina Nakamori | MEIKO NAKAHARA   \n",
       "186  watch?v= | Akina Nakamori | MEIKO NAKAHARA   \n",
       "\n",
       "                                                  body  \n",
       "0    Listen to the album of this. It is also good. ...  \n",
       "1    It's my second favorite of his after Ride On T...  \n",
       "2    I like *Weekend Fly to the Sun* because every ...  \n",
       "3          Enjoy! My favorite track is “Street Dancer”  \n",
       "4    So lucky I love love love this album . what a ...  \n",
       "..                                                 ...  \n",
       "182  [tatsuro yamashita live at festival hall](http...  \n",
       "183  Koi No Projection\\tis one of my favs. [here it...  \n",
       "184  Compare to [Masayoshi Takanaka –  Star Wars Sa...  \n",
       "185  [Lonely Sunset](https://www.youtube.com/watch?...  \n",
       "186  Hideki Saijo - Careless Whisper\\n\\nhttps://www...  \n",
       "\n",
       "[187 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_centroids['centroid_element'] = df_centroids['centroid_element'].apply(lambda x : x.split(' || '))\n",
    "df_centroids = df_centroids.explode('centroid_element')\n",
    "\n",
    "\n",
    "test = pd.merge(df_centroids, df_clusters, left_on = 'centroid_element', right_on = 'id')\n",
    "test = pd.merge(test, comments, on = 'id')\n",
    "test = test[['lemma_2', 'body']]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c029700-87c4-4fd0-a333-1b2710fb7e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd57edc-4d4d-4bde-9eb8-9126f6e49cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b5dc2-faea-4d91-b1aa-2c8e24f2135b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3493c-a312-4937-bdc7-24f4793f4b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469211fe-b669-4447-90c1-461dc06e19bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bddd8-10d3-476f-a7c7-7eaf48c80b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

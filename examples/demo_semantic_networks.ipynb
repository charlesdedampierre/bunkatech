{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d462192-16d8-4be2-973c-1ec007accd59",
   "metadata": {},
   "source": [
    "# Semantic Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfae428-8324-4511-8398-90e1b4b70740",
   "metadata": {},
   "source": [
    "Use networks to study the interactions between categories and terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef78971-66a1-44ab-a900-b0ee599fe039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../bunkatech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5391d4a9-9adb-46e9-9b48-677296216ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesdedampierre/Desktop/BUNKA Project/bunkatech/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bunkatech.networks import SemanticNetworks\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "\n",
    "data = pd.read_csv('../data/imdb.csv', index_col = [0])\n",
    "data = data.sample(2000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c8c629-f4bd-4b0b-a159-2738b8606ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata = data[['imdb', 'description', 'genre', 'country']].copy().dropna()\\ndata['genre'] = data['genre'].apply(lambda x: x.split(', '))\\ndata['country'] = data['country'].apply(lambda x: x.split(', '))\\ndata = data.explode('genre')\\ndata = data.explode('country')\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data = data[['imdb', 'description', 'genre', 'country']].copy().dropna()\n",
    "data['genre'] = data['genre'].apply(lambda x: x.split(', '))\n",
    "data['country'] = data['country'].apply(lambda x: x.split(', '))\n",
    "data = data.explode('genre')\n",
    "data = data.explode('country')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d94ebe6f-6c8a-4606-bfd8-6b2471b5b9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                   | 0/1991 [00:00<?, ?it/s]2022-11-18 17:55:06,719 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-11-18 17:55:06,766 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-11-18 17:55:06,805 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-11-18 17:55:06,806 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-11-18 17:55:06,845 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-11-18 17:55:06,882 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "  0%|                                                                         | 1/1991 [00:05<3:06:49,  5.63s/it]2022-11-18 17:55:06,955 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-11-18 17:55:06,979 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "100%|███████████████████████████████████████████████████████████████████████| 1991/1991 [00:08<00:00, 241.43it/s]\n",
      "2022-11-18 17:55:09,827 - INFO : Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2022-11-18 17:55:10,119 - INFO : Use pytorch device: cpu\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████| 63/63 [00:01<00:00, 33.84it/s]\n",
      "2022-11-18 17:55:11,992 - INFO : Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 17:55:12,206 - INFO : Use pytorch device: cpu\n",
      "2022-11-18 17:55:12,207 - INFO : CUDA is not available. Start 4 CPU worker\n",
      "2022-11-18 17:55:12,207 - INFO : Start multi-process pool on devices: cpu, cpu, cpu, cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "UMAP(n_components=5, verbose=True)\n",
      "Fri Nov 18 17:55:21 2022 Construct fuzzy simplicial set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 18 17:55:23 2022 Finding Nearest Neighbors\n",
      "Fri Nov 18 17:55:24 2022 Finished Nearest Neighbor Search\n",
      "Fri Nov 18 17:55:25 2022 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed: 100%| █████████████████████████████████████████████████████████████████████████ 500/500 [00:01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 18 17:55:28 2022 Finished embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nets = SemanticNetworks(data = data,\n",
    "                        text_var = 'description',\n",
    "                        index_var = 'imdb',\n",
    "                        extract_terms=True,\n",
    "                        terms_embedding=True,\n",
    "                        docs_embedding=True,\n",
    "                        sample_size_terms=2000,\n",
    "                        terms_limit=2000,\n",
    "                        terms_ents=False,\n",
    "                        terms_ngrams=(2, 2),\n",
    "                        terms_ncs=False,\n",
    "                        terms_include_pos=[\"NOUN\", \"PROPN\", \"ADJ\"],\n",
    "                        terms_include_types=[\"PERSON\", \"ORG\"],\n",
    "                        terms_embedding_model=\"all-MiniLM-L6-v2\",\n",
    "                        docs_embedding_model=\"all-MiniLM-L6-v2\",\n",
    "                        language=\"en\",\n",
    "                        terms_path=None,\n",
    "                        docs_dimension_reduction = 5,\n",
    "                        terms_embeddings_path=None,\n",
    "                        docs_embeddings_path=None,\n",
    "                        docs_multiprocessing = True,\n",
    "                        terms_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea22341-5de0-4384-afa6-55079fa49757",
   "metadata": {},
   "source": [
    "#### Draw the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35cc340-fdba-41ce-a621-3469bfed2d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|███████████████████████████████████| 404/404 [00:00<00:00, 12899.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|████████████████████████████████████| 419/419 [00:00<00:00, 3025.04it/s]\n",
      "\n",
      "Generating walks (CPU: 1):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 2):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:00<00:00, 12.41it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:00<00:00, 12.64it/s]\n",
      "Generating walks (CPU: 5):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:00<00:00, 12.72it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:00<00:00, 12.77it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:00<00:00, 12.80it/s]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:00<00:00, 12.93it/s]"
     ]
    }
   ],
   "source": [
    "fig = nets.fit_draw(top_n=500,\n",
    "                    variables = ['main form'], \n",
    "                    global_filter=0.2, # Minimum cosine for two nodes to be connected\n",
    "                    n_neighbours=8, # minimum number of neightbours a node is directed to\n",
    "                    method=\"node2vec\", # Use Node2Vec or force_directed algorithm\n",
    "                    n_cluster=15,\n",
    "                    bin_number=30,\n",
    "                    black_hole_force=1, # Add a force to make the clusters aggregate\n",
    "                    color=\"community\", # 'community' for clusters or 'entity' for node_type\n",
    "                    size=\"size\",\n",
    "                    symbol=\"entity\",\n",
    "                    textfont_size=9,\n",
    "                    edge_size=0.5,\n",
    "                    height=2000,\n",
    "                    width=2000,\n",
    "                    template=\"plotly_dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe761e2-8c20-447a-b0b7-140c91429929",
   "metadata": {},
   "source": [
    "#### Save the plots as an html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94d3b5f0-35a1-4bff-b6e2-e4489a2ac261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'filename.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import plotly \n",
    "\n",
    "plotly.offline.plot(fig, filename = 'filename.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359fdf8-762a-4c35-85a7-2c29970de07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

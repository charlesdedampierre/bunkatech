{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d462192-16d8-4be2-973c-1ec007accd59",
   "metadata": {},
   "source": [
    "# Semantic Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfae428-8324-4511-8398-90e1b4b70740",
   "metadata": {},
   "source": [
    "Use networks to study the interactions between categories and terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5391d4a9-9adb-46e9-9b48-677296216ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bunkatech.networks import SemanticNetworks\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "    \n",
    "data = pd.read_csv('../data/imdb.csv', index_col = [0])\n",
    "data = data.sample(2000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c8c629-f4bd-4b0b-a159-2738b8606ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata = data[['imdb', 'description', 'genre', 'country']].copy().dropna()\\ndata['genre'] = data['genre'].apply(lambda x: x.split(', '))\\ndata['country'] = data['country'].apply(lambda x: x.split(', '))\\ndata = data.explode('genre')\\ndata = data.explode('country')\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data = data[['imdb', 'description', 'genre', 'country']].copy().dropna()\n",
    "data['genre'] = data['genre'].apply(lambda x: x.split(', '))\n",
    "data['country'] = data['country'].apply(lambda x: x.split(', '))\n",
    "data = data.explode('genre')\n",
    "data = data.explode('country')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d94ebe6f-6c8a-4606-bfd8-6b2471b5b9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                 | 0/1991 [00:00<?, ?it/s]2022-03-30 15:43:21,884 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-03-30 15:43:21,899 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-03-30 15:43:21,911 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-03-30 15:43:21,912 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-03-30 15:43:21,918 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-03-30 15:43:21,923 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-03-30 15:43:21,937 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "2022-03-30 15:43:21,942 - INFO : loaded 'en_core_web_sm' spaCy language pipeline\n",
      "100%|█████████████████████████████████████████████████████| 1991/1991 [00:08<00:00, 222.79it/s]\n",
      "2022-03-30 15:43:24,628 - INFO : Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2022-03-30 15:43:30,743 - INFO : Use pytorch device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2bb72bcae448bfa4b28f5031d0179c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 15:43:38,842 - INFO : Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 15:43:45,762 - INFO : Use pytorch device: cpu\n",
      "2022-03-30 15:43:45,763 - INFO : CUDA is not available. Start 4 CPU worker\n",
      "2022-03-30 15:43:45,763 - INFO : Start multi-process pool on devices: cpu, cpu, cpu, cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 15:43:50,940 - INFO : Chunk data into packages of size 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(n_components=5, verbose=True)\n",
      "Wed Mar 30 15:44:05 2022 Construct fuzzy simplicial set\n",
      "Wed Mar 30 15:44:07 2022 Finding Nearest Neighbors\n",
      "Wed Mar 30 15:44:08 2022 Finished Nearest Neighbor Search\n",
      "Wed Mar 30 15:44:10 2022 Construct embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f612c718afd4df19eb0289c0559be0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/500 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 30 15:44:12 2022 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "nets = SemanticNetworks(data = data,\n",
    "                        text_var = 'description',\n",
    "                        index_var = 'imdb',\n",
    "                        extract_terms=True,\n",
    "                        terms_embedding=True,\n",
    "                        docs_embedding=True,\n",
    "                        sample_size_terms=2000,\n",
    "                        terms_limit=2000,\n",
    "                        terms_ents=False,\n",
    "                        terms_ngrams=(2, 2),\n",
    "                        terms_ncs=False,\n",
    "                        terms_include_pos=[\"NOUN\", \"PROPN\", \"ADJ\"],\n",
    "                        terms_include_types=[\"PERSON\", \"ORG\"],\n",
    "                        terms_embedding_model=\"all-MiniLM-L6-v2\",\n",
    "                        docs_embedding_model=\"all-MiniLM-L6-v2\",\n",
    "                        language=\"en\",\n",
    "                        terms_path=None,\n",
    "                        docs_dimension_reduction = 5,\n",
    "                        terms_embeddings_path=None,\n",
    "                        docs_embeddings_path=None,\n",
    "                        docs_multiprocessing = True,\n",
    "                        terms_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea22341-5de0-4384-afa6-55079fa49757",
   "metadata": {},
   "source": [
    "#### Draw the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35cc340-fdba-41ce-a621-3469bfed2d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd8e1686f3044bb8b0cfd7905a2a785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:00<00:00, 11.10it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:00<00:00, 11.19it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:00<00:00, 11.18it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:00<00:00, 10.86it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:00<00:00, 11.20it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:00<00:00, 11.18it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:00<00:00, 11.23it/s]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:00<00:00, 10.91it/s]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:00<00:00, 11.30it/s]\n",
      "2022-03-30 15:59:22,413 - INFO : collecting all words and their counts\n",
      "2022-03-30 15:59:22,414 - INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-30 15:59:22,445 - INFO : collected 398 word types from a corpus of 318400 raw words and 3980 sentences\n",
      "2022-03-30 15:59:22,445 - INFO : Creating a fresh vocabulary\n",
      "2022-03-30 15:59:22,447 - INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 398 unique words (100.0%% of original 398, drops 0)', 'datetime': '2022-03-30T15:59:22.447359', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-30 15:59:22,447 - INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 318400 word corpus (100.0%% of original 318400, drops 0)', 'datetime': '2022-03-30T15:59:22.447646', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-30 15:59:22,449 - INFO : deleting the raw counts dictionary of 398 items\n",
      "2022-03-30 15:59:22,449 - INFO : sample=0.001 downsamples 125 most-common words\n",
      "2022-03-30 15:59:22,449 - INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 270386.2764679182 word corpus (84.9%% of prior 318400)', 'datetime': '2022-03-30T15:59:22.449923', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-30 15:59:22,453 - INFO : estimated required memory for 398 words and 700 dimensions: 2427800 bytes\n",
      "2022-03-30 15:59:22,453 - INFO : resetting layer weights\n",
      "2022-03-30 15:59:22,455 - INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-30T15:59:22.455587', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-30 15:59:22,456 - INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 398 vocabulary and 700 features, using sg=1 hs=0 sample=0.001 negative=5 window=30 shrink_windows=True', 'datetime': '2022-03-30T15:59:22.456020', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-30 15:59:23,904 - INFO : EPOCH 1 - PROGRESS: at 34.55% examples, 64767 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-30 15:59:24,651 - INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-03-30 15:59:24,685 - INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-03-30 15:59:24,694 - INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-03-30 15:59:24,698 - INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-03-30 15:59:24,704 - INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-03-30 15:59:24,710 - INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-03-30 15:59:24,713 - INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-30 15:59:24,721 - INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-30 15:59:25,002 - INFO : EPOCH 1 - PROGRESS: at 96.86% examples, 103112 words/s, in_qsize 1, out_qsize 1\n",
      "2022-03-30 15:59:25,003 - INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-30 15:59:25,055 - INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-30 15:59:25,056 - INFO : EPOCH - 1 : training on 318400 raw words (270471 effective words) took 2.6s, 104274 effective words/s\n",
      "2022-03-30 15:59:26,451 - INFO : EPOCH 2 - PROGRESS: at 34.55% examples, 67177 words/s, in_qsize 20, out_qsize 0\n",
      "2022-03-30 15:59:27,269 - INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-03-30 15:59:27,304 - INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-03-30 15:59:27,339 - INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-03-30 15:59:27,367 - INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-03-30 15:59:27,368 - INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-03-30 15:59:27,371 - INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-03-30 15:59:27,386 - INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-30 15:59:27,405 - INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-30 15:59:27,603 - INFO : EPOCH 2 - PROGRESS: at 96.86% examples, 102962 words/s, in_qsize 1, out_qsize 1\n",
      "2022-03-30 15:59:27,604 - INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-30 15:59:27,637 - INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-30 15:59:27,637 - INFO : EPOCH - 2 : training on 318400 raw words (270480 effective words) took 2.6s, 104963 effective words/s\n",
      "2022-03-30 15:59:28,964 - INFO : EPOCH 3 - PROGRESS: at 34.55% examples, 70544 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-30 15:59:29,667 - INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-03-30 15:59:29,673 - INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-03-30 15:59:29,674 - INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-03-30 15:59:29,678 - INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-03-30 15:59:29,699 - INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-03-30 15:59:29,701 - INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-03-30 15:59:29,723 - INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-30 15:59:29,737 - INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-30 15:59:29,980 - INFO : EPOCH 3 - PROGRESS: at 96.86% examples, 111885 words/s, in_qsize 1, out_qsize 1\n",
      "2022-03-30 15:59:29,981 - INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-30 15:59:30,017 - INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-30 15:59:30,017 - INFO : EPOCH - 3 : training on 318400 raw words (270312 effective words) took 2.4s, 113760 effective words/s\n",
      "2022-03-30 15:59:31,310 - INFO : EPOCH 4 - PROGRESS: at 34.55% examples, 72366 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-30 15:59:32,046 - INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-03-30 15:59:32,055 - INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-03-30 15:59:32,063 - INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-03-30 15:59:32,067 - INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-03-30 15:59:32,074 - INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-03-30 15:59:32,096 - INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-03-30 15:59:32,098 - INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-30 15:59:32,120 - INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-30 15:59:32,341 - INFO : EPOCH 4 - PROGRESS: at 96.86% examples, 112915 words/s, in_qsize 1, out_qsize 1\n",
      "2022-03-30 15:59:32,341 - INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-30 15:59:32,389 - INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-30 15:59:32,390 - INFO : EPOCH - 4 : training on 318400 raw words (270486 effective words) took 2.4s, 114189 effective words/s\n",
      "2022-03-30 15:59:33,690 - INFO : EPOCH 5 - PROGRESS: at 34.55% examples, 71973 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-30 15:59:34,398 - INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-03-30 15:59:34,434 - INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-03-30 15:59:34,435 - INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-03-30 15:59:34,435 - INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-03-30 15:59:34,438 - INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-03-30 15:59:34,444 - INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-03-30 15:59:34,460 - INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-30 15:59:34,539 - INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-30 15:59:34,700 - INFO : EPOCH 5 - PROGRESS: at 96.86% examples, 113589 words/s, in_qsize 1, out_qsize 1\n",
      "2022-03-30 15:59:34,700 - INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-30 15:59:34,746 - INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-30 15:59:34,746 - INFO : EPOCH - 5 : training on 318400 raw words (270584 effective words) took 2.4s, 115003 effective words/s\n",
      "2022-03-30 15:59:34,747 - INFO : Word2Vec lifecycle event {'msg': 'training on 1592000 raw words (1352333 effective words) took 12.3s, 110028 effective words/s', 'datetime': '2022-03-30T15:59:34.747142', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-30 15:59:34,747 - INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=398, vector_size=700, alpha=0.025)', 'datetime': '2022-03-30T15:59:34.747390', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e74170a26784777bf9162a81ec08977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:00<00:00, 10.34it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:00<00:00, 10.56it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:00<00:00, 10.41it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:00<00:00, 10.61it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:00<00:00, 10.52it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:00<00:00, 10.15it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:00<00:00, 10.71it/s]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:00<00:00, 10.85it/s]\n",
      "2022-03-30 15:59:35,554 - INFO : collecting all words and their counts\n",
      "2022-03-30 15:59:35,555 - INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-30 15:59:35,585 - INFO : collected 413 word types from a corpus of 330400 raw words and 4130 sentences\n",
      "2022-03-30 15:59:35,585 - INFO : Creating a fresh vocabulary\n",
      "2022-03-30 15:59:35,586 - INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 413 unique words (100.0%% of original 413, drops 0)', 'datetime': '2022-03-30T15:59:35.586819', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-30 15:59:35,587 - INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 330400 word corpus (100.0%% of original 330400, drops 0)', 'datetime': '2022-03-30T15:59:35.587078', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-30 15:59:35,588 - INFO : deleting the raw counts dictionary of 413 items\n",
      "2022-03-30 15:59:35,589 - INFO : sample=0.001 downsamples 133 most-common words\n",
      "2022-03-30 15:59:35,589 - INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 279688.7635817874 word corpus (84.7%% of prior 330400)', 'datetime': '2022-03-30T15:59:35.589401', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-30 15:59:35,592 - INFO : estimated required memory for 413 words and 700 dimensions: 2519300 bytes\n",
      "2022-03-30 15:59:35,592 - INFO : resetting layer weights\n",
      "2022-03-30 15:59:35,594 - INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-30T15:59:35.594037', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-30 15:59:35,594 - INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 413 vocabulary and 700 features, using sg=1 hs=0 sample=0.001 negative=5 window=30 shrink_windows=True', 'datetime': '2022-03-30T15:59:35.594271', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-30 15:59:36,947 - INFO : EPOCH 1 - PROGRESS: at 33.29% examples, 69021 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-30 15:59:37,630 - INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-03-30 15:59:37,639 - INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-03-30 15:59:37,649 - INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-03-30 15:59:37,651 - INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-03-30 15:59:37,652 - INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-03-30 15:59:37,709 - INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-03-30 15:59:37,740 - INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-30 15:59:37,997 - INFO : EPOCH 1 - PROGRESS: at 93.95% examples, 109550 words/s, in_qsize 2, out_qsize 1\n",
      "2022-03-30 15:59:37,998 - INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-30 15:59:38,008 - INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-30 15:59:38,010 - INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-30 15:59:38,010 - INFO : EPOCH - 1 : training on 330400 raw words (279824 effective words) took 2.4s, 115998 effective words/s\n",
      "2022-03-30 15:59:39,283 - INFO : EPOCH 2 - PROGRESS: at 33.29% examples, 73554 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-30 15:59:40,049 - INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-03-30 15:59:40,060 - INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-03-30 15:59:40,076 - INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-03-30 15:59:40,085 - INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-03-30 15:59:40,099 - INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-03-30 15:59:40,103 - INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-03-30 15:59:40,123 - INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-30 15:59:40,387 - INFO : EPOCH 2 - PROGRESS: at 93.95% examples, 110777 words/s, in_qsize 2, out_qsize 1\n",
      "2022-03-30 15:59:40,388 - INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-30 15:59:40,454 - INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-30 15:59:40,464 - INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-30 15:59:40,464 - INFO : EPOCH - 2 : training on 330400 raw words (279848 effective words) took 2.5s, 114201 effective words/s\n",
      "2022-03-30 15:59:41,798 - INFO : EPOCH 3 - PROGRESS: at 33.29% examples, 69869 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-30 15:59:42,530 - INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-03-30 15:59:42,543 - INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-03-30 15:59:42,544 - INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-03-30 15:59:42,552 - INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-03-30 15:59:42,582 - INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-03-30 15:59:42,598 - INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-03-30 15:59:42,609 - INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-30 15:59:42,944 - INFO : EPOCH 3 - PROGRESS: at 93.95% examples, 106118 words/s, in_qsize 2, out_qsize 1\n",
      "2022-03-30 15:59:42,945 - INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-30 15:59:42,945 - INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-30 15:59:42,964 - INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-30 15:59:42,964 - INFO : EPOCH - 3 : training on 330400 raw words (279789 effective words) took 2.5s, 112101 effective words/s\n",
      "2022-03-30 15:59:44,261 - INFO : EPOCH 4 - PROGRESS: at 33.29% examples, 71994 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-30 15:59:45,066 - INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-03-30 15:59:45,086 - INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-03-30 15:59:45,101 - INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-03-30 15:59:45,123 - INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-03-30 15:59:45,124 - INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-03-30 15:59:45,151 - INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-03-30 15:59:45,181 - INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-30 15:59:45,371 - INFO : EPOCH 4 - PROGRESS: at 93.95% examples, 109403 words/s, in_qsize 2, out_qsize 1\n",
      "2022-03-30 15:59:45,371 - INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-30 15:59:45,456 - INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-30 15:59:45,481 - INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-30 15:59:45,481 - INFO : EPOCH - 4 : training on 330400 raw words (279881 effective words) took 2.5s, 111356 effective words/s\n",
      "2022-03-30 15:59:46,798 - INFO : EPOCH 5 - PROGRESS: at 33.29% examples, 70817 words/s, in_qsize 19, out_qsize 0\n",
      "2022-03-30 15:59:47,525 - INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2022-03-30 15:59:47,532 - INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2022-03-30 15:59:47,533 - INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2022-03-30 15:59:47,564 - INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2022-03-30 15:59:47,572 - INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2022-03-30 15:59:47,574 - INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2022-03-30 15:59:47,604 - INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-03-30 15:59:47,911 - INFO : EPOCH 5 - PROGRESS: at 93.95% examples, 108300 words/s, in_qsize 2, out_qsize 1\n",
      "2022-03-30 15:59:47,912 - INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-30 15:59:47,935 - INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-30 15:59:47,943 - INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-30 15:59:47,943 - INFO : EPOCH - 5 : training on 330400 raw words (279682 effective words) took 2.5s, 113773 effective words/s\n",
      "2022-03-30 15:59:47,944 - INFO : Word2Vec lifecycle event {'msg': 'training on 1652000 raw words (1399024 effective words) took 12.3s, 113284 effective words/s', 'datetime': '2022-03-30T15:59:47.944245', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-30 15:59:47,944 - INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=413, vector_size=700, alpha=0.025)', 'datetime': '2022-03-30T15:59:47.944486', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "fig = nets.fit_draw(top_n=500,\n",
    "                    variables = ['main form'], \n",
    "                    global_filter=0.2, # Minimum cosine for two nodes to be connected\n",
    "                    n_neighbours=8, # minimum number of neightbours a node is directed to\n",
    "                    method=\"node2vec\", # Use Node2Vec or force_directed algorithm\n",
    "                    n_cluster=15,\n",
    "                    bin_number=30,\n",
    "                    black_hole_force=1, # Add a force to make the clusters aggregate\n",
    "                    color=\"community\", # 'community' for clusters or 'entity' for node_type\n",
    "                    size=\"size\",\n",
    "                    symbol=\"entity\",\n",
    "                    textfont_size=9,\n",
    "                    edge_size=0.5,\n",
    "                    height=2000,\n",
    "                    width=2000,\n",
    "                    template=\"plotly_dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe761e2-8c20-447a-b0b7-140c91429929",
   "metadata": {},
   "source": [
    "#### Save the plots as an html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d3b5f0-35a1-4bff-b6e2-e4489a2ac261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'filename.html'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly \n",
    "\n",
    "plotly.offline.plot(fig, filename = 'filename.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a359fdf8-762a-4c35-85a7-2c29970de07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

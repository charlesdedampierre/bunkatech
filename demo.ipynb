{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bamboolib\n",
    "import plotly\n",
    "import warnings\n",
    "\n",
    "from bunkatech.networks.networks import network_analysis\n",
    "\n",
    "from bunkatech.semantics.extract_terms import extract_terms_df\n",
    "from bunkatech.semantics.indexer import indexer\n",
    "from bunkatech.semantics.get_embeddings import get_embeddings\n",
    "\n",
    "from bunkatech.hierarchical_clusters import hierarchical_clusters\n",
    "from bunkatech.hierarchical_clusters_label import hierarchical_clusters_label\n",
    "\n",
    "from bunkatech.visualization.make_bubble import make_bubble\n",
    "from bunkatech.visualization.sankey import make_sankey\n",
    "from bunkatech.visualization.topics_treemap import topics_treemap\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('data/imdb_movies.csv', index_col = [0])\n",
    "\n",
    "text_var = 'description'\n",
    "index_var = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Terms from the a specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = extract_terms_df(\n",
    "        df,\n",
    "        text_var=text_var,\n",
    "        limit=2000,\n",
    "        sample_size=3000,\n",
    "        ngs=True, #ngrams\n",
    "        ents=False, #entities\n",
    "        ncs=True, #nouns\n",
    "        drop_emoji=True,\n",
    "        remove_punctuation=False,\n",
    "        ngrams=(2, 2),\n",
    "        include_pos=[\"NOUN\", \"PROPN\", \"ADJ\"],\n",
    "        include_types=[\"PERSON\", \"ORG\"],\n",
    "        language=\"en\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index terms extracted to the original corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3be98e3cffd483d975de68281259fcf"
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docs</th>\n",
       "      <th>lemma</th>\n",
       "      <th>main form</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Stoneman family finds its friendship with ...</td>\n",
       "      <td>civil war</td>\n",
       "      <td>Civil War</td>\n",
       "      <td>civil war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A manipulative woman and a roguish man conduct...</td>\n",
       "      <td>civil war</td>\n",
       "      <td>Civil War</td>\n",
       "      <td>civil war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>During the Spanish Civil War, an American alli...</td>\n",
       "      <td>civil war</td>\n",
       "      <td>Civil War</td>\n",
       "      <td>civil war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An American Civil War veteran embarks on a jou...</td>\n",
       "      <td>civil war</td>\n",
       "      <td>Civil War</td>\n",
       "      <td>civil war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A family saga covering several decades of West...</td>\n",
       "      <td>civil war</td>\n",
       "      <td>Civil War</td>\n",
       "      <td>civil war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>Set in the small-town of Bareilly, Bitti is a ...</td>\n",
       "      <td>pritam vidrohi</td>\n",
       "      <td>Pritam Vidrohi</td>\n",
       "      <td>Pritam Vidrohi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>Before NYC, college valedictorian Ben visits h...</td>\n",
       "      <td>loser dad</td>\n",
       "      <td>Loser dad</td>\n",
       "      <td>Loser dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>Before NYC, college valedictorian Ben visits h...</td>\n",
       "      <td>loser dad</td>\n",
       "      <td>Loser dad</td>\n",
       "      <td>loser dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>Before NYC, college valedictorian Ben visits h...</td>\n",
       "      <td>park loser</td>\n",
       "      <td>park loser</td>\n",
       "      <td>park loser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>Competing in a Christmas baking competition in...</td>\n",
       "      <td>prince's fiancée</td>\n",
       "      <td>prince's fiancée</td>\n",
       "      <td>prince's fiancée</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9756 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   docs             lemma  \\\n",
       "0     The Stoneman family finds its friendship with ...         civil war   \n",
       "1     A manipulative woman and a roguish man conduct...         civil war   \n",
       "2     During the Spanish Civil War, an American alli...         civil war   \n",
       "3     An American Civil War veteran embarks on a jou...         civil war   \n",
       "4     A family saga covering several decades of West...         civil war   \n",
       "...                                                 ...               ...   \n",
       "9751  Set in the small-town of Bareilly, Bitti is a ...    pritam vidrohi   \n",
       "9752  Before NYC, college valedictorian Ben visits h...         loser dad   \n",
       "9753  Before NYC, college valedictorian Ben visits h...         loser dad   \n",
       "9754  Before NYC, college valedictorian Ben visits h...        park loser   \n",
       "9755  Competing in a Christmas baking competition in...  prince's fiancée   \n",
       "\n",
       "             main form              text  \n",
       "0            Civil War         civil war  \n",
       "1            Civil War         civil war  \n",
       "2            Civil War         civil war  \n",
       "3            Civil War         civil war  \n",
       "4            Civil War         civil war  \n",
       "...                ...               ...  \n",
       "9751    Pritam Vidrohi    Pritam Vidrohi  \n",
       "9752         Loser dad         Loser dad  \n",
       "9753         Loser dad         loser dad  \n",
       "9754        park loser        park loser  \n",
       "9755  prince's fiancée  prince's fiancée  \n",
       "\n",
       "[9756 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Index with the list of original words\n",
    "df_terms = terms.copy()\n",
    "df_terms['text'] = df_terms['text'].apply(lambda x: x.split(' | '))\n",
    "df_terms = df_terms.explode('text').reset_index(drop=True)\n",
    "list_terms = df_terms['text'].tolist()\n",
    "\n",
    "df_indexed = indexer(df[text_var].tolist(), list_terms, db_path = '.')\n",
    "\n",
    "# get the Main form and the lemma\n",
    "df_indexed_full = pd.merge(df_indexed, df_terms, left_on = 'words', right_on = 'text')\n",
    "df_indexed_full = df_indexed_full[['docs', 'lemma', 'main form', 'text']].copy()\n",
    "\n",
    "df_indexed_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cooccurrence Graph Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saved_graph/category_cooccurence.html'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_graph = df[['imdb', 'genre', 'country']].copy()\n",
    "\n",
    "df_graph = df_graph.dropna()\n",
    "df_graph['genre'] = df_graph['genre'].apply(lambda x: x.split(','))\n",
    "df_graph = df_graph.explode('genre')\n",
    "\n",
    "df_graph['country'] = df_graph['country'].apply(lambda x: x.split(','))\n",
    "df_graph = df_graph.explode('country')\n",
    "\n",
    "\n",
    "fig = network_analysis(\n",
    "        df_graph,\n",
    "        variables=[\"genre\", \"country\"],\n",
    "        key=\"imdb\",\n",
    "        top_nodes=500,\n",
    "        global_filter=0.2,\n",
    "        n_neighbours=5,\n",
    "        method=\"force_directed\",\n",
    "        density=10,\n",
    "        height_att=1500,\n",
    "        width_att=1500,\n",
    "        color=\"community\",\n",
    "        template=\"simple_white\",\n",
    "        edge_size=1.5,\n",
    "        symbol=\"entity\",\n",
    "        save_path=\".\",\n",
    "    )\n",
    "\n",
    "plotly.offline.plot(\n",
    "        fig, auto_open=True, filename=\"saved_graph/category_cooccurence.html\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cooccurrence Graph terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saved_graph/terms_cooccurence.html'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_graph_terms = pd.merge(df_indexed, df, left_on = 'docs', right_on = 'description')\n",
    "df_graph_terms = df_graph_terms[['imdb', 'words']].copy()\n",
    "\n",
    "fig = network_analysis(\n",
    "        df_graph_terms,\n",
    "        variables=[\"words\"],\n",
    "        key=\"imdb\",\n",
    "        top_nodes=200,\n",
    "        global_filter=0,\n",
    "        n_neighbours=10,\n",
    "        method=\"force_directed\",\n",
    "        density=3,\n",
    "        height_att=1500,\n",
    "        width_att=1500,\n",
    "        color=\"community\",\n",
    "        template=\"simple_white\",\n",
    "        edge_size=1.5,\n",
    "        symbol=None,\n",
    "        save_path=\".\",\n",
    "    )\n",
    "\n",
    "plotly.offline.plot(\n",
    "        fig, auto_open=True, filename=\"saved_graph/terms_cooccurence.html\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings..\n",
      "Reducing the vectors..\n",
      "UMAP(angular_rp_forest=True, metric='cosine', n_components=5, n_neighbors=10, verbose=True)\n",
      "Thu Feb 10 11:01:33 2022 Construct fuzzy simplicial set\n",
      "Thu Feb 10 11:01:33 2022 Finding Nearest Neighbors\n",
      "Thu Feb 10 11:01:33 2022 Building RP forest with 10 trees\n",
      "Thu Feb 10 11:01:36 2022 metric NN descent for 13 iterations\n",
      "\t 1  /  13\n",
      "\t 2  /  13\n",
      "\t 3  /  13\n",
      "\t 4  /  13\n",
      "\t 5  /  13\n",
      "\t 6  /  13\n",
      "\t 7  /  13\n",
      "\t 8  /  13\n",
      "\t 9  /  13\n",
      "\t 10  /  13\n",
      "\t 11  /  13\n",
      "\tStopping threshold met -- exiting after 11 iterations\n",
      "Thu Feb 10 11:03:03 2022 Finished Nearest Neighbor Search\n",
      "Thu Feb 10 11:03:12 2022 Construct embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68cd4059c0c464c9e1d44bfcdfb12bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/500 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 10 11:03:41 2022 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "df_sample = df.sample(9000, random_state = 42)\n",
    "df_sample = df_sample[df_sample[text_var].notna()].reset_index(drop=True) # cautious not to let any nan\n",
    "\n",
    "embeddings_reduced, full_embeddings = get_embeddings(\n",
    "    df_sample,\n",
    "    field=text_var,\n",
    "    model=\"tfidf\",\n",
    "    model_path=\"distiluse-base-multilingual-cased-v1\",#workds if sbert is chosen\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterize & plot embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP Reduction...\n"
     ]
    }
   ],
   "source": [
    "fig = make_bubble(embeddings_reduced, df_sample, text_var= 'description', n_clusters=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Nested Embeddings & give them names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Nested clusters.\n",
    "\n",
    "df_emb = pd.DataFrame(embeddings_reduced)\n",
    "df_emb['imdb'] = df_sample['imdb']\n",
    "h_clusters = hierarchical_clusters(df_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with terms extracted previously\n",
    "df_enrich = pd.merge(df_sample, df_indexed_full, left_on = text_var, right_on = 'docs')\n",
    "df_enrich = df_enrich[['imdb', 'main form']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge clusters and original dataset\n",
    "h_clusters_label = pd.merge(h_clusters, df_enrich, on = 'imdb')\n",
    "h_clusters_label = h_clusters_label.rename(columns = {'main form':'lemma'})\n",
    "h_clusters_names = hierarchical_clusters_label(h_clusters_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Treemap Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topics_treemap(nested_topics = h_clusters_names)\n",
    "plotly.offline.plot(\n",
    "        fig, auto_open=True, filename=\"saved_graph/treemap.html\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Sankey Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_sankey(h_clusters_names, field = 'imdb Movies', index_var = 'imdb')\n",
    "plotly.offline.plot(\n",
    "        fig, auto_open=True, filename=\"saved_graph/sankey.html\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
